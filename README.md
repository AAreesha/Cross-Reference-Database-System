# Cross-Reference-Database-System

**AI-Integrated Cross-Reference Database System**
Connect. Embed. Search.

---

## ğŸ“„ Overview

This project is an AI-accelerated cross-reference infrastructure that unifies four large datasets into a single searchable system.
It supports semantic search powered by OpenAI embeddings, ensuring fast, scalable, and intelligent retrieval.

Built using:

* **PostgreSQL** with **pgvector** extension (for vector storage and similarity search)
* **Redis** (for intelligent caching)
* **FastAPI** backend (Python)
* **React.js** frontend (JavaScript)
* **Docker Compose** (for full containerization)

The system enables:

* Cross-linking references between multiple databases
* AI-driven record embedding generation
* Fast semantic search using cosine similarity
* Intelligent query caching to boost performance
* Simple web UI for user-friendly access

---

## ğŸ› ï¸ Step-by-Step Setup Guide

### âœ… STEP 1: Install Docker

#### ğŸ”¹ For Windows:

1. Visit [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
2. Download and install Docker Desktop.
3. Launch Docker Desktop and ensure it shows "Docker is running."
4. Confirm installation by running:

```bash
docker --version
```

Expected output:

```
Docker version XX.XX.X, build xxxxxxx
```

---

### âœ… STEP 2: Create `.env` File

Create a `.env` file at the project root with the following content. (.env.sample) template also present for your ease of use:

```env
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/unified_db
REDIS_URL=redis://redis:6379/0
REACT_APP_API_URL=http://localhost:8000
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

This file securely stores config values used by Docker and FastAPI.

---

### âœ… STEP 3: Docker Setup for PostgreSQL + Redis

Docker Compose auto-pulls required containers:

#### ğŸƒ PostgreSQL with pgvector:

* Image: `ankane/pgvector`
* Initializes schema via `database/db-init.sql`
* Table: `unified_index`
* Extension: `pgvector`
* Index: cosine-based `ivfflat`

To manually pull:

```bash
docker pull ankane/pgvector
```

#### ğŸ”„ Redis:

* Image: `redis:alpine`
* Default port: `6379`

To manually pull:

```bash
docker pull redis:alpine
```

---

### âœ… STEP 4: Run the Full Stack

From your terminal, run:

```bash
docker-compose up --build
```

Expected output includes:

* PostgreSQL initializing
* Redis starting
* FastAPI available at: `http://localhost:8000/docs`

To stop:

```bash
CTRL + C
```

Then:

```bash
docker-compose down
```

---

## ğŸ“‚ Project Structure

```
project-root/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile              # Builds FastAPI container
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py             # Entry point, includes route setup
â”‚       â”œâ”€â”€ db.py               # PostgreSQL connection via SQLAlchemy
â”‚       â”œâ”€â”€ models.py           # ORM definition of unified_index
â”‚       â”œâ”€â”€ routes.py           # API endpoints
â”‚       â”œâ”€â”€ utils.py            # OpenAI embedding generation
â”‚       â””â”€â”€ cache.py            # Redis caching utilities
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ db-init.sql             # SQL to create table, extension, index
â”‚
â”œâ”€â”€ .env                        # Main env file
â”œâ”€â”€ .env.sample                 # Sample env (exclude API keys)
â”œâ”€â”€ docker-compose.yml          # Docker orchestration file
â””â”€â”€ README.md                   # This documentation
```

---

## âœ… Backend Development Walkthrough (vs Client Requirements)

### ğŸ—ï¸ Step 1: Database Initialization

* Created: `database/db-init.sql`
* Table: `unified_index`
* Columns: `id, db1_id, db2_id, db3_id, db4_id, embedding, created_at`
* Enabled: `pgvector`, cosine-based `ivfflat` index

### ğŸ˜ Step 2: PostgreSQL Container

* Image: `ankane/pgvector`
* Port: `5432`
* Auto-runs `db-init.sql`

### â™»ï¸ Step 3: Redis Container

* Image: `redis:alpine`
* Port: `6379`
* TTL: 3600 seconds for search cache

### âš™ï¸ Step 4: Backend App (FastAPI)

* Created: `backend/app/`
* Files: `main.py, db.py, models.py, routes.py, utils.py, cache.py`

### ğŸ“¦ Step 5: PostgreSQL via SQLAlchemy

* File: `db.py`
* Reads: `DATABASE_URL` from `.env`

### ğŸ“ Step 6: SQLAlchemy ORM

* File: `models.py`
* Model: `UnifiedIndex`
* Uses: `Vector(1536)` from `pgvector`

### âš¡ Step 7: Redis Caching Utility

* File: `cache.py`
* Functions: `get_cached_result()`, `set_cached_result()`
* TTL: 3600 seconds

### ğŸ§ Step 8: OpenAI Embedding

* File: `utils.py`
* Function: `generate_embedding(text)`
* API: `text-embedding-3-small`

### ğŸ”— Step 9: API Routes

* File: `routes.py`
* `/insert-record/`: generates + stores embedding
* `/semantic-search/`: searches via cosine similarity

  * Checks Redis first
  * If not cached, queries DB
  * Caches and returns top 5 results

### ğŸ« Step 10: Dockerization

* File: `backend/Dockerfile`
* Exposes: `8000`
* Injects: `.env` config
* Added to: `docker-compose.yml`

---

## ğŸ“… Final Test

Visit: `http://localhost:8000/docs`

* Try `/insert-record/`
* Try `/semantic-search/`
* Confirm:

  * Embeddings are generated via OpenAI
  * Caching logic via Redis
  * Fast vector similarity search via pgvector

---

## ğŸ“Š Client Delivery Checklist

| Requirement                  | Status | Notes                              |
| ---------------------------- | ------ | ---------------------------------- |
| pgvector + Postgres setup    | âœ… Done | Indexed, init script works         |
| Redis with TTL 3600s         | âœ… Done | Caching system integrated          |
| Insert/Search endpoints      | âœ… Done | Auto-generates embedding           |
| OpenAI embedding integration | âœ… Done | Uses text-embedding-3-small        |
| Dockerized backend           | âœ… Done | Clean build with .env support      |
| Modular Python code          | âœ… Done | All files organized in `/app/`     |
| .env.sample                  | âœ… Done | Provided (manual confirm contents) |
| Semantic cosine search       | âœ… Done | Top 5 matches using vector index   |

---

## ğŸ”— Useful Links

* OpenAI API Key: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
* Docker: [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
* Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
